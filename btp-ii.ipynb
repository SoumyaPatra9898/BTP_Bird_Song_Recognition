{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:11.103536Z",
     "iopub.status.busy": "2022-04-27T11:44:11.102872Z",
     "iopub.status.idle": "2022-04-27T11:44:20.438423Z",
     "shell.execute_reply": "2022-04-27T11:44:20.437528Z",
     "shell.execute_reply.started": "2022-04-27T11:44:11.103435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing all the libraries necessary for the project\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook; tqdm.pandas()\n",
    "import jax\n",
    "import torchvision\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "import jax.nn\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "import warnings\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from typing import Any\n",
    "import functools\n",
    "from flax.training import train_state\n",
    "# to suppress warnings caused by cuda version\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:26.426302Z",
     "iopub.status.busy": "2022-04-27T11:44:26.426019Z",
     "iopub.status.idle": "2022-04-27T11:44:26.641105Z",
     "shell.execute_reply": "2022-04-27T11:44:26.640409Z",
     "shell.execute_reply.started": "2022-04-27T11:44:26.426251Z"
    }
   },
   "outputs": [],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:29.320124Z",
     "iopub.status.busy": "2022-04-27T11:44:29.319361Z",
     "iopub.status.idle": "2022-04-27T11:44:29.326081Z",
     "shell.execute_reply": "2022-04-27T11:44:29.325338Z",
     "shell.execute_reply.started": "2022-04-27T11:44:29.320083Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:31.936002Z",
     "iopub.status.busy": "2022-04-27T11:44:31.935678Z",
     "iopub.status.idle": "2022-04-27T11:44:31.945788Z",
     "shell.execute_reply": "2022-04-27T11:44:31.944833Z",
     "shell.execute_reply.started": "2022-04-27T11:44:31.935966Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = \"/kaggle/input/birdsong-recognition/\"\n",
    "os.listdir(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:36.305555Z",
     "iopub.status.busy": "2022-04-27T11:44:36.305245Z",
     "iopub.status.idle": "2022-04-27T11:44:36.741986Z",
     "shell.execute_reply": "2022-04-27T11:44:36.741187Z",
     "shell.execute_reply.started": "2022-04-27T11:44:36.305507Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(ROOT, 'train.csv'))[['ebird_code', 'filename', 'duration']]\n",
    "df['path'] = ROOT+'train_audio/' + df['ebird_code'] + \"/\" + df['filename']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:45.744067Z",
     "iopub.status.busy": "2022-04-27T11:44:45.743768Z",
     "iopub.status.idle": "2022-04-27T11:44:45.756826Z",
     "shell.execute_reply": "2022-04-27T11:44:45.755960Z",
     "shell.execute_reply.started": "2022-04-27T11:44:45.744037Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FRAC = 0.2     # Validation fraction\n",
    "SR = 44100     # sampling rate\n",
    "MAXLEN= 60    # seconds\n",
    "N_MELS = 128\n",
    "\n",
    "seed_everything(SEED)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "#Random sample of 15 birds\n",
    "classes = set(random.sample(df['ebird_code'].unique().tolist(), 10)) \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:47.130658Z",
     "iopub.status.busy": "2022-04-27T11:44:47.129852Z",
     "iopub.status.idle": "2022-04-27T11:44:47.156995Z",
     "shell.execute_reply": "2022-04-27T11:44:47.156284Z",
     "shell.execute_reply.started": "2022-04-27T11:44:47.130618Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df.ebird_code.apply(lambda x: x in classes)].reset_index(drop=True)\n",
    "keys = set(df.ebird_code)\n",
    "values = np.arange(0, len(keys))\n",
    "code_dict = dict(zip(sorted(keys), values))\n",
    "df['label'] = df['ebird_code'].apply(lambda x: code_dict[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:50.626569Z",
     "iopub.status.busy": "2022-04-27T11:44:50.625990Z",
     "iopub.status.idle": "2022-04-27T11:44:50.642225Z",
     "shell.execute_reply": "2022-04-27T11:44:50.641496Z",
     "shell.execute_reply.started": "2022-04-27T11:44:50.626527Z"
    }
   },
   "outputs": [],
   "source": [
    "class BirdSoundDataset(Dataset):\n",
    "    \"\"\"Bird Sound dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): must have ['path', 'label'] columns\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def loadMP3(self, path, duration):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: path of the audio file \n",
    "        Returns:\n",
    "            mels: Melspectrogram of the given audio file \n",
    "        \"\"\"\n",
    "        try:\n",
    "            duration=5\n",
    "            samples = SR* duration\n",
    "            audio, _ = librosa.load(path, sr=SR)\n",
    "            if 0 < len(audio):\n",
    "                audio, _ = librosa.effects.trim(audio)\n",
    "            if len(audio) > samples: # long enough\n",
    "                audio = audio[0:0+samples]\n",
    "            else: # pad blank\n",
    "                padding = samples - len(audio)\n",
    "                offset = padding // 2\n",
    "                y = np.pad(audio, (offset, samples - len(audio) - offset), 'constant')\n",
    "\n",
    "            mels = librosa.feature.melspectrogram(y=audio, sr=SR,n_mels=N_MELS, hop_length = 347,n_fft = N_MELS *20,fmin = 20, fmax = SR//2)\n",
    "            mels = librosa.power_to_db(mels).astype(np.float32)\n",
    "            mels = mels.transpose()\n",
    "            eps = 0.001\n",
    "            if np.std(mels) != 0:\n",
    "                mels = (mels - np.mean(mels)) / np.std(mels)\n",
    "            else:\n",
    "                mels = (mels - np.mean(mels)) / eps\n",
    "            return mels\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file: \", path, e)\n",
    "            mels = np.zeros((N_MELS, MAXLEN*SR//347), dtype=np.float32)\n",
    "            return mels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        path = self.df['path'].iloc[idx]\n",
    "    \n",
    "        duration=5\n",
    "        if os.path.exists(\"./\"+path.split('/')[-1]+\".npy\"):\n",
    "            mels = np.load(\"./\"+path.split('/')[-1]+\".npy\")\n",
    "        else:\n",
    "            \n",
    "            mels = self.loadMP3(path, duration)\n",
    "            np.save(\"./\"+path.split('/')[-1]+\".npy\", mels)\n",
    "        label  = self.df['label'].iloc[idx]\n",
    "        mels = np.resize(mels,(636,128,1))\n",
    "        return mels, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:52.959892Z",
     "iopub.status.busy": "2022-04-27T11:44:52.959224Z",
     "iopub.status.idle": "2022-04-27T11:44:52.971111Z",
     "shell.execute_reply": "2022-04-27T11:44:52.970369Z",
     "shell.execute_reply.started": "2022-04-27T11:44:52.959856Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train_len = int(len(df) * (1-FRAC))\n",
    "train_df = df.iloc[:train_len]\n",
    "valid_df = df.iloc[train_len:]\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:44:59.545375Z",
     "iopub.status.busy": "2022-04-27T11:44:59.545079Z",
     "iopub.status.idle": "2022-04-27T11:44:59.554378Z",
     "shell.execute_reply": "2022-04-27T11:44:59.553318Z",
     "shell.execute_reply.started": "2022-04-27T11:44:59.545342Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(BirdSoundDataset(train_df),\n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           num_workers=0, \n",
    "                                           shuffle=True, \n",
    "                                           drop_last = True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(BirdSoundDataset(valid_df), \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           num_workers=0, \n",
    "                                           shuffle=True, \n",
    "                                           drop_last = True)\n",
    "\n",
    "len(train_loader), len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:45:03.789319Z",
     "iopub.status.busy": "2022-04-27T11:45:03.788500Z",
     "iopub.status.idle": "2022-04-27T11:45:42.159412Z",
     "shell.execute_reply": "2022-04-27T11:45:42.158348Z",
     "shell.execute_reply.started": "2022-04-27T11:45:03.789273Z"
    }
   },
   "outputs": [],
   "source": [
    "(image_batch, label_batch) = next(iter(train_loader))\n",
    "print(image_batch.shape)\n",
    "print(label_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:46:23.211430Z",
     "iopub.status.busy": "2022-04-27T11:46:23.210925Z",
     "iopub.status.idle": "2022-04-27T11:59:12.540553Z",
     "shell.execute_reply": "2022-04-27T11:59:12.539082Z",
     "shell.execute_reply.started": "2022-04-27T11:46:23.211385Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TPUS = jax.device_count()\n",
    "\n",
    "def copy_dataset_to_devices(dataset, devices, num_reps=1):\n",
    "    sharded_images = []\n",
    "    sharded_labels = []\n",
    "    for _ in range(num_reps):\n",
    "        for image_batch, label_batch in tqdm(dataset, ncols=100):\n",
    "            image_batch = image_batch.detach().cpu().numpy()\n",
    "            image_batches = np.split(image_batch, NUM_TPUS, axis = 0)\n",
    "            sharded_device_images = jax.device_put_sharded(image_batches, devices)\n",
    "            sharded_images.append(sharded_device_images)\n",
    "\n",
    "            label_batch = label_batch.detach().cpu().numpy()\n",
    "            label_batches = np.split(label_batch, NUM_TPUS, axis = 0)\n",
    "            sharded_device_labels = jax.device_put_sharded(label_batches, devices)\n",
    "            sharded_labels.append(sharded_device_labels)\n",
    "\n",
    "    return sharded_images, sharded_labels\n",
    "\n",
    "devices = jax.local_devices()\n",
    "print(\"NUM_TPUS:\",NUM_TPUS)\n",
    "sharded_training_images, sharded_training_labels = copy_dataset_to_devices(train_loader, devices, num_reps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:52.070035Z",
     "iopub.status.busy": "2022-04-27T11:59:52.069162Z",
     "iopub.status.idle": "2022-04-27T11:59:52.088558Z",
     "shell.execute_reply": "2022-04-27T11:59:52.087708Z",
     "shell.execute_reply.started": "2022-04-27T11:59:52.069995Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "class VGG19(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x, training):\n",
    "        x = self._stack(x, 64, training)\n",
    "        x = self._stack(x, 64, training)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    \n",
    "        x = self._stack(x, 128, training)\n",
    "        x = self._stack(x, 128, training)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        x = self._stack(x, 256, training)\n",
    "        x = self._stack(x, 256, training)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))    \n",
    "\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))    \n",
    "    \n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = self._stack(x, 512, training)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))  \n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "\n",
    "        x = nn.Dense(features=4096)(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(0.5, deterministic=not training)(x)\n",
    "\n",
    "        x = nn.Dense(features=4096)(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(0.5, deterministic=not training)(x)\n",
    "    \n",
    "        x = nn.Dense(features=NUM_CLASSES)(x)\n",
    "        return x\n",
    "  \n",
    "    @staticmethod\n",
    "    def _stack(x, features, training, dropout=None):\n",
    "        x = nn.Conv(features=features, kernel_size=(3, 3), padding='SAME')(x)\n",
    "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:53.396424Z",
     "iopub.status.busy": "2022-04-27T11:59:53.395810Z",
     "iopub.status.idle": "2022-04-27T11:59:53.403010Z",
     "shell.execute_reply": "2022-04-27T11:59:53.402131Z",
     "shell.execute_reply.started": "2022-04-27T11:59:53.396382Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_metrics(metrics):\n",
    "    '''\n",
    "    Takes the list of dictionaries of the form k: v, and returns a dictionary\n",
    "     of the form k: (average of the v).\n",
    "    '''\n",
    "    return {k: np.mean([metric[k] for metric in metrics])\n",
    "        for k in metrics[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:55.002204Z",
     "iopub.status.busy": "2022-04-27T11:59:55.001474Z",
     "iopub.status.idle": "2022-04-27T11:59:55.009132Z",
     "shell.execute_reply": "2022-04-27T11:59:55.008343Z",
     "shell.execute_reply.started": "2022-04-27T11:59:55.002164Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(initial_network_state, num_epochs):\n",
    "    '''\n",
    "    Training the model from the given state, returns the state along with the training accuracies\n",
    "    '''\n",
    "    training_accuracies = []\n",
    "    state = initial_network_state\n",
    "    for i in range(num_epochs):\n",
    "        batch_metrics = []\n",
    "        for (image_batch, label_batch) in tqdm(zip(sharded_training_images,\n",
    "                                               sharded_training_labels),\n",
    "                                           total=len(sharded_training_images),\n",
    "                                           ncols=100):\n",
    "            state, metrics = train_batch(state, image_batch, label_batch)\n",
    "            batch_metrics.append(metrics)\n",
    "        train_metrics = average_metrics(batch_metrics)\n",
    "        print(f'Epoch {i+1} done.', flush=True)\n",
    "        print(f'  Loss: {train_metrics[\"loss\"]:.4f}, '\n",
    "          + f'accuracy: {train_metrics[\"accuracy\"]:.4f}', flush=True)\n",
    "        training_accuracies.append(train_metrics[\"accuracy\"])\n",
    "    return state, training_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:56.932665Z",
     "iopub.status.busy": "2022-04-27T11:59:56.932361Z",
     "iopub.status.idle": "2022-04-27T11:59:56.942191Z",
     "shell.execute_reply": "2022-04-27T11:59:56.941339Z",
     "shell.execute_reply.started": "2022-04-27T11:59:56.932635Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGGState(train_state.TrainState):\n",
    "    rng: Any\n",
    "    batch_stats: Any\n",
    "  \n",
    "    @classmethod\n",
    "    def create(cls, apply_fn, params, tx, rng, batch_stats):\n",
    "        opt_state = tx.init(params)\n",
    "        state = cls(0, apply_fn, params, tx, opt_state, rng, batch_stats)\n",
    "        return state\n",
    "  \n",
    "    @classmethod\n",
    "    def update_rng(cls, state, rng):\n",
    "        return VGGState.create(state.apply_fn, state.params, state.tx, rng,\n",
    "                           state.batch_stats)\n",
    "  \n",
    "    @classmethod\n",
    "    def update_batch_stats(cls, state, batch_stats):\n",
    "        return VGGState.create(state.apply_fn, state.params, state.tx,\n",
    "                           state.rng, batch_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:58.125782Z",
     "iopub.status.busy": "2022-04-27T11:59:58.125163Z",
     "iopub.status.idle": "2022-04-27T11:59:58.135386Z",
     "shell.execute_reply": "2022-04-27T11:59:58.134335Z",
     "shell.execute_reply.started": "2022-04-27T11:59:58.125740Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    '''\n",
    "    Calcualtes the accuracy using the given logits and labels\n",
    "    '''\n",
    "    return jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "\n",
    "def cross_entropy(logits, labels):\n",
    "    '''\n",
    "    Cross Entropy error between the logits and labels\n",
    "    '''\n",
    "    one_hot_labels = jax.nn.one_hot(labels, NUM_CLASSES)\n",
    "    cross_entropy = optax.softmax_cross_entropy(logits, one_hot_labels)\n",
    "    return jnp.mean(cross_entropy)\n",
    "\n",
    "def training_loss(image_batch, label_batch, rng, batch_stats, params):\n",
    "    '''\n",
    "    Calculates the training loss \n",
    "    '''\n",
    "    logits, batch_stats = VGG19().apply({'params': params,\n",
    "                                       'batch_stats': batch_stats},\n",
    "                                      image_batch, \n",
    "                                      training=True,\n",
    "                                      rngs={'dropout': rng},\n",
    "                                      mutable=['batch_stats'])\n",
    "    loss = cross_entropy(logits, label_batch)\n",
    "    return loss, (logits, batch_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:59:59.969728Z",
     "iopub.status.busy": "2022-04-27T11:59:59.969036Z",
     "iopub.status.idle": "2022-04-27T11:59:59.978383Z",
     "shell.execute_reply": "2022-04-27T11:59:59.977478Z",
     "shell.execute_reply.started": "2022-04-27T11:59:59.969685Z"
    }
   },
   "outputs": [],
   "source": [
    "@functools.partial(jax.pmap, axis_name='tpu')\n",
    "def train_batch(state, image_batch, label_batch):\n",
    "    '''\n",
    "    Training a single batch and returns loss and the accuracy\n",
    "    '''\n",
    "    rng, subrng = jax.random.split(state.rng)\n",
    "    batch_loss_fn = functools.partial(training_loss, image_batch, label_batch,\n",
    "                                    subrng, state.batch_stats)\n",
    "    (batch_loss, (logits, batch_stats)), grads = \\\n",
    "    jax.value_and_grad(batch_loss_fn, has_aux=True)(state.params)\n",
    "  \n",
    "    gradsum = jax.lax.psum(grads, axis_name='tpu')\n",
    "\n",
    "    state = state.apply_gradients(grads=gradsum)\n",
    "    state = state.update_batch_stats(state, batch_stats['batch_stats'])\n",
    "    state = state.update_rng(state, rng)\n",
    "\n",
    "    batch_accuracy = accuracy(logits=logits, labels=label_batch)\n",
    "    batch_accuracy_sum = jax.lax.pmean(batch_accuracy, axis_name='tpu')\n",
    "    batch_loss = jax.lax.psum(batch_loss, axis_name='tpu')\n",
    "    stats = {'loss': batch_loss, 'accuracy': batch_accuracy_sum}  \n",
    "\n",
    "    return state, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T12:00:01.678555Z",
     "iopub.status.busy": "2022-04-27T12:00:01.677419Z",
     "iopub.status.idle": "2022-04-27T12:00:01.685051Z",
     "shell.execute_reply": "2022-04-27T12:00:01.684215Z",
     "shell.execute_reply.started": "2022-04-27T12:00:01.678501Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_state(rng, dummy_image_batch):\n",
    "    net = VGG19()\n",
    "    params = net.init({'params': rng, 'dropout': rng}, dummy_image_batch, True)\n",
    "    tx = optax.adam(learning_rate=0.01)\n",
    "    state = VGGState.create(net.apply, params['params'], tx, rng,\n",
    "                          params['batch_stats'])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T12:00:06.161363Z",
     "iopub.status.busy": "2022-04-27T12:00:06.160839Z",
     "iopub.status.idle": "2022-04-27T12:00:14.506453Z",
     "shell.execute_reply": "2022-04-27T12:00:14.505654Z",
     "shell.execute_reply.started": "2022-04-27T12:00:06.161327Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "rngs = np.broadcast_to(rng, (NUM_TPUS,) + rng.shape)\n",
    "some_dummy_image_batch = sharded_training_images[0]\n",
    "state = jax.pmap(create_train_state, axis_name='gpu')(rngs,some_dummy_image_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T12:00:31.246775Z",
     "iopub.status.busy": "2022-04-27T12:00:31.246493Z",
     "iopub.status.idle": "2022-04-27T12:40:14.807425Z",
     "shell.execute_reply": "2022-04-27T12:40:14.806328Z",
     "shell.execute_reply.started": "2022-04-27T12:00:31.246745Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "final_state, training_accuracies = train(state, num_epochs=25)\n",
    "print(\"Total time: \", time.time() - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T12:48:35.541144Z",
     "iopub.status.busy": "2022-04-27T12:48:35.540862Z",
     "iopub.status.idle": "2022-04-27T12:48:35.746805Z",
     "shell.execute_reply": "2022-04-27T12:48:35.746123Z",
     "shell.execute_reply.started": "2022-04-27T12:48:35.541116Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(training_accuracies)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:04:58.973791Z",
     "iopub.status.busy": "2022-04-24T12:04:58.973126Z",
     "iopub.status.idle": "2022-04-24T12:04:58.982486Z",
     "shell.execute_reply": "2022-04-24T12:04:58.981727Z",
     "shell.execute_reply.started": "2022-04-24T12:04:58.973753Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Class to handle all HMM related processing\n",
    "class HMMTrainer(object):\n",
    "    def __init__(self, model_name='GaussianHMM', n_components=4, cov_type='diag', n_iter=1000):\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components,\n",
    "                                         covariance_type=self.cov_type, n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "\n",
    "    # X is a 2D numpy array where each row is 13D\n",
    "    def train(self, X):\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X))\n",
    "\n",
    "    # Run the model on input data\n",
    "    def get_score(self, input_data):\n",
    "        return self.model.score(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:05:43.045803Z",
     "iopub.status.busy": "2022-04-24T12:05:43.045479Z",
     "iopub.status.idle": "2022-04-24T12:05:43.068056Z",
     "shell.execute_reply": "2022-04-24T12:05:43.067118Z",
     "shell.execute_reply.started": "2022-04-24T12:05:43.04577Z"
    }
   },
   "outputs": [],
   "source": [
    "class SigProc():\n",
    "    def __init__(self,filename):\n",
    "        self.filename = filename\n",
    "        self.signal, self.sr = librosa.load(filename)\n",
    "        self.logMMSE = self.LogMMSE()\n",
    "        self.MFCCs = self.MFCC()\n",
    "\n",
    "    def LogMMSE(self):\n",
    "        x = self.signal\n",
    "        Slen = int(np.floor(0.02 * self.sr)) - 1\n",
    "        noise_frames = 6\n",
    "\n",
    "        PERC = 50\n",
    "        len1 = int(np.floor(Slen * PERC / 100))\n",
    "        len2 = Slen - len1\n",
    "\n",
    "        win = np.hanning(Slen)\n",
    "        win = win * len2 / np.sum(win)\n",
    "        nFFT = 2 * Slen\n",
    "\n",
    "        x_old = np.zeros(len1)\n",
    "        Xk_prev = np.zeros(len1)\n",
    "        Nframes = int(np.floor(len(x) / len2) - np.floor(Slen / len2))\n",
    "        xfinal = np.zeros(Nframes * len2)\n",
    "\n",
    "        noise_mean = np.zeros(nFFT)\n",
    "        for j in range(0, Slen * noise_frames, Slen):\n",
    "            noise_mean = noise_mean + np.absolute(np.fft.fft(win * x[j:j + Slen], nFFT, axis=0))\n",
    "        noise_mu2 = noise_mean / noise_frames ** 2\n",
    "\n",
    "        aa = 0.98\n",
    "        mu = 0.98\n",
    "        eta = 0.15\n",
    "        ksi_min = 10 ** (-25 / 10)\n",
    "\n",
    "        for k in range(0, Nframes * len2, len2):\n",
    "            insign = win * x[k:k + Slen]\n",
    "\n",
    "            spec = np.fft.fft(insign, nFFT, axis=0)\n",
    "            sig = np.absolute(spec)\n",
    "            sig2 = sig ** 2\n",
    "\n",
    "            gammak = np.minimum(sig2 / noise_mu2, 40)\n",
    "\n",
    "            if Xk_prev.all() == 0:\n",
    "                ksi = aa + (1 - aa) * np.maximum(gammak - 1, 0)\n",
    "            else:\n",
    "                ksi = aa * Xk_prev / noise_mu2 + (1 - aa) * np.maximum(gammak - 1, 0)\n",
    "                ksi = np.maximum(ksi_min, ksi)\n",
    "\n",
    "            log_sigma_k = gammak * ksi / (1 + ksi) - np.log(1 + ksi)\n",
    "            vad_decision = np.sum(log_sigma_k) / Slen\n",
    "            if (vad_decision < eta):\n",
    "                noise_mu2 = mu * noise_mu2 + (1 - mu) * sig2\n",
    "\n",
    "            A = ksi / (1 + ksi)\n",
    "            vk = A * gammak\n",
    "            ei_vk = 0.5 * scipy.special.expn(1, vk)\n",
    "            hw = A * np.exp(ei_vk)\n",
    "\n",
    "            sig = sig * hw\n",
    "            Xk_prev = sig ** 2\n",
    "            xi_w = np.fft.ifft(hw * spec, nFFT, axis=0)\n",
    "            xi_w = np.real(xi_w)\n",
    "\n",
    "            xfinal[k:k + len2] = x_old + xi_w[0:len1]\n",
    "            x_old = xi_w[len1:Slen]\n",
    "\n",
    "        if not np.isnan(xfinal[0]):\n",
    "            return xfinal\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def MFCC(self):\n",
    "        MFCC = librosa.feature.mfcc(y=self.logMMSE, sr=self.sr, n_mfcc=40)\n",
    "        return MFCC\n",
    "\n",
    "def PlotImg(signal,sr,logMMSE,MFCCs):\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    plt.rcParams['figure.figsize'] = (7, 6)\n",
    "\n",
    "    plt.subplot(311)\n",
    "    librosa.display.waveplot(signal, sr=sr)\n",
    "    plt.title('Raw Wave')\n",
    "\n",
    "    plt.subplot(312)\n",
    "    librosa.display.waveplot(logMMSE, sr=sr)\n",
    "    plt.title('MMSE-LSA')\n",
    "\n",
    "    plt.subplot(313)\n",
    "    librosa.display.specshow(MFCCs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()\n",
    "    img = 'waveforms/{}.png'.format(int(time.time()))\n",
    "    plt.savefig('/app/'+img)\n",
    "    plt.close()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMM import *\n",
    "from tqdm import tqdm\n",
    "from sigproc import SigProc\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def train_wavs(data_folder):\n",
    "    hmm_models = []\n",
    "    test_set = []\n",
    "    for dirname in os.listdir(data_folder):\n",
    "        # Get the name of the subfolder\n",
    "        subfolder = os.path.join(data_folder, dirname)\n",
    "        if not os.path.isdir(subfolder):\n",
    "            continue\n",
    "        # Extract the label\n",
    "        label = subfolder[subfolder.rfind('/') + 1:]\n",
    "        print('[*] '+label)\n",
    "        # Initialize variables\n",
    "        X = np.array([])\n",
    "        y_words = []\n",
    "\n",
    "        # Iterate through the audio files (leaving 1 file for testing in each class)\n",
    "        files = [x for x in os.listdir(subfolder) if x.endswith('.wav')]\n",
    "        #train_set = files[:-2]\n",
    "        #test_set.append([os.path.join(subfolder,i) for i in files[-2:]])\n",
    "        for filename in tqdm(train_set):\n",
    "            # Extract Feature\n",
    "            print \n",
    "            filepath = os.path.join(subfolder,filename)\n",
    "            try:\n",
    "                mfcc_features = SigProc(filepath).MFCC().T\n",
    "            except:\n",
    "                pass\n",
    "            # Append to the variable X\n",
    "            if len(X) == 0:\n",
    "                X = mfcc_features\n",
    "            else:\n",
    "                X = np.append(X, mfcc_features, axis=0)\n",
    "\n",
    "            # Append the label\n",
    "            y_words.append(label)\n",
    "\n",
    "        # Train and save HMM model\n",
    "        hmm_trainer = HMMTrainer()\n",
    "        hmm_trainer.train(X)\n",
    "        hmm_models.append((hmm_trainer, label))\n",
    "        joblib.dump(hmm_trainer, subfolder + \"/ModelTrained.pkl\")\n",
    "        hmm_trainer = None\n",
    "    return test_set\n",
    "\n",
    "def recognize(mfcc_features):\n",
    "    # Load Models\n",
    "    hmm_models = []\n",
    "\n",
    "    data_folder = '/app/data'\n",
    "    for dirname in os.listdir(data_folder):\n",
    "        # Get the name of the subfolder\n",
    "        subfolder = os.path.join(data_folder, dirname)\n",
    "        if not os.path.isdir(subfolder):\n",
    "            continue\n",
    "        # Extract the label\n",
    "        label = subfolder[subfolder.rfind('/') + 1:]\n",
    "        hmm_model = joblib.load(subfolder + \"/ModelTrained.pkl\")\n",
    "        hmm_models.append((hmm_model, label))\n",
    "\n",
    "\n",
    "    # Define variables\n",
    "    max_score = -10000000000000.0\n",
    "    output_label = None\n",
    "\n",
    "    # Iterate through all HMM models and pick\n",
    "    # the one with the highest score\n",
    "    for item in hmm_models:\n",
    "        hmm_model, label = item\n",
    "        score = hmm_model.get_score(mfcc_features.T)\n",
    "        if score > float(max_score):\n",
    "            max_score = score\n",
    "            output_label = label\n",
    "    print(output_label)\n",
    "    return output_label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = '/app/data'\n",
    "    train_wavs(data_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
